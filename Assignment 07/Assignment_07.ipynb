{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Assignment No. 07 - Text Analysis\n",
    "\n",
    "#   1. Extract Sample document and apply following document preprocessing methods:\n",
    "#   Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.\n",
    "#   2. Create representation of document by calculating Term Frequency and Inverse Document Frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   importing libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sklearn as sk\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   Run those commands once to download library dependencies\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Scarlett O'Hara was not beautiful, but men seldom realized it when caught by her charm as the Tarleton twins were. In her face were too sharply blended the delicate features of her mother, a Coast aristocrat of French descent, and the heavy ones of her florid Irish father. But it was an arresting face, pointed of chin, square of jaw. Her eyes were pale green without a touch of hazel, starred with bristly black lashes and slightly tilted at the ends. Above them, her thick black brows slanted upward, cutting a startling oblique line in her magnolia-white skin--that skin so prized by Southern women and so carefully guarded with bonnets, veils and mittens against hot Georgia suns.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   Create a sample text\n",
    "text = \"Scarlett O'Hara was not beautiful, but men seldom realized it when caught by her charm as the Tarleton twins were. In her face were too sharply blended the delicate features of her mother, a Coast aristocrat of French descent, and the heavy ones of her florid Irish father. But it was an arresting face, pointed of chin, square of jaw. Her eyes were pale green without a touch of hazel, starred with bristly black lashes and slightly tilted at the ends. Above them, her thick black brows slanted upward, cutting a startling oblique line in her magnolia-white skin--that skin so prized by Southern women and so carefully guarded with bonnets, veils and mittens against hot Georgia suns.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text: \n",
      "\n",
      "['Scarlett', \"O'Hara\", 'was', 'not', 'beautiful', ',', 'but', 'men', 'seldom', 'realized', 'it', 'when', 'caught', 'by', 'her', 'charm', 'as', 'the', 'Tarleton', 'twins', 'were', '.', 'In', 'her', 'face', 'were', 'too', 'sharply', 'blended', 'the', 'delicate', 'features', 'of', 'her', 'mother', ',', 'a', 'Coast', 'aristocrat', 'of', 'French', 'descent', ',', 'and', 'the', 'heavy', 'ones', 'of', 'her', 'florid', 'Irish', 'father', '.', 'But', 'it', 'was', 'an', 'arresting', 'face', ',', 'pointed', 'of', 'chin', ',', 'square', 'of', 'jaw', '.', 'Her', 'eyes', 'were', 'pale', 'green', 'without', 'a', 'touch', 'of', 'hazel', ',', 'starred', 'with', 'bristly', 'black', 'lashes', 'and', 'slightly', 'tilted', 'at', 'the', 'ends', '.', 'Above', 'them', ',', 'her', 'thick', 'black', 'brows', 'slanted', 'upward', ',', 'cutting', 'a', 'startling', 'oblique', 'line', 'in', 'her', 'magnolia-white', 'skin', '--', 'that', 'skin', 'so', 'prized', 'by', 'Southern', 'women', 'and', 'so', 'carefully', 'guarded', 'with', 'bonnets', ',', 'veils', 'and', 'mittens', 'against', 'hot', 'Georgia', 'suns', '.']\n",
      "\n",
      "Tokenized Sentence: \n",
      "\n",
      "[\"Scarlett O'Hara was not beautiful, but men seldom realized it when caught by her charm as the Tarleton twins were.\", 'In her face were too sharply blended the delicate features of her mother, a Coast aristocrat of French descent, and the heavy ones of her florid Irish father.', 'But it was an arresting face, pointed of chin, square of jaw.', 'Her eyes were pale green without a touch of hazel, starred with bristly black lashes and slightly tilted at the ends.', 'Above them, her thick black brows slanted upward, cutting a startling oblique line in her magnolia-white skin--that skin so prized by Southern women and so carefully guarded with bonnets, veils and mittens against hot Georgia suns.']\n"
     ]
    }
   ],
   "source": [
    "#   Tokenization\n",
    "tokenized_text = nltk.word_tokenize(text)\n",
    "print(\"Tokenized Text: \\n\")\n",
    "print(tokenized_text)\n",
    "\n",
    "tokenized_sent = nltk.sent_tokenize(text)\n",
    "print(\"\\nTokenized Sentence: \\n\")\n",
    "print(tokenized_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Scarlett', 'NOUN'), (\"O'Hara\", 'NOUN'), ('was', 'VERB'), ('not', 'ADV'), ('beautiful', 'ADJ'), (',', '.'), ('but', 'CONJ'), ('men', 'NOUN'), ('seldom', 'ADV'), ('realized', 'VERB'), ('it', 'PRON'), ('when', 'ADV'), ('caught', 'VERB'), ('by', 'ADP'), ('her', 'PRON'), ('charm', 'NOUN'), ('as', 'ADP'), ('the', 'DET'), ('Tarleton', 'NOUN'), ('twins', 'NOUN'), ('were', 'VERB'), ('.', '.')], [('In', 'ADP'), ('her', 'PRON'), ('face', 'NOUN'), ('were', 'VERB'), ('too', 'ADV'), ('sharply', 'ADV'), ('blended', 'VERB'), ('the', 'DET'), ('delicate', 'ADJ'), ('features', 'NOUN'), ('of', 'ADP'), ('her', 'PRON'), ('mother', 'NOUN'), (',', '.'), ('a', 'DET'), ('Coast', 'NOUN'), ('aristocrat', 'NOUN'), ('of', 'ADP'), ('French', 'ADJ'), ('descent', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('the', 'DET'), ('heavy', 'ADJ'), ('ones', 'NOUN'), ('of', 'ADP'), ('her', 'PRON'), ('florid', 'ADJ'), ('Irish', 'ADJ'), ('father', 'NOUN'), ('.', '.')], [('But', 'CONJ'), ('it', 'PRON'), ('was', 'VERB'), ('an', 'DET'), ('arresting', 'ADJ'), ('face', 'NOUN'), (',', '.'), ('pointed', 'VERB'), ('of', 'ADP'), ('chin', 'NOUN'), (',', '.'), ('square', 'NOUN'), ('of', 'ADP'), ('jaw', 'NOUN'), ('.', '.')], [('Her', 'PRON'), ('eyes', 'NOUN'), ('were', 'VERB'), ('pale', 'ADJ'), ('green', 'ADJ'), ('without', 'ADP'), ('a', 'DET'), ('touch', 'NOUN'), ('of', 'ADP'), ('hazel', 'NOUN'), (',', '.'), ('starred', 'VERB'), ('with', 'ADP'), ('bristly', 'ADV'), ('black', 'ADJ'), ('lashes', 'NOUN'), ('and', 'CONJ'), ('slightly', 'ADV'), ('tilted', 'VERB'), ('at', 'ADP'), ('the', 'DET'), ('ends', 'NOUN'), ('.', '.')], [('Above', 'ADP'), ('them', 'PRON'), (',', '.'), ('her', 'PRON'), ('thick', 'ADJ'), ('black', 'ADJ'), ('brows', 'NOUN'), ('slanted', 'VERB'), ('upward', 'ADV'), (',', '.'), ('cutting', 'VERB'), ('a', 'DET'), ('startling', 'ADJ'), ('oblique', 'ADJ'), ('line', 'NOUN'), ('in', 'ADP'), ('her', 'PRON'), ('magnolia-white', 'ADJ'), ('skin', 'NOUN'), ('--', '.'), ('that', 'DET'), ('skin', 'VERB'), ('so', 'ADV'), ('prized', 'VERB'), ('by', 'ADP'), ('Southern', 'ADJ'), ('women', 'NOUN'), ('and', 'CONJ'), ('so', 'ADV'), ('carefully', 'ADV'), ('guarded', 'VERB'), ('with', 'ADP'), ('bonnets', 'NOUN'), (',', '.'), ('veils', 'NOUN'), ('and', 'CONJ'), ('mittens', 'NOUN'), ('against', 'ADP'), ('hot', 'ADJ'), ('Georgia', 'NOUN'), ('suns', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "#   POS Tagging - Part of Speech Tagging\n",
    "\n",
    "words = [nltk.word_tokenize(i) for i in nltk.sent_tokenize(text)]\n",
    "pos_tag = [nltk.pos_tag(i, tagset=\"universal\") for i in words]\n",
    "print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text: \n",
      "\n",
      " ['Scarlett', \"O'Hara\", 'was', 'not', 'beautiful', ',', 'but', 'men', 'seldom', 'realized', 'it', 'when', 'caught', 'by', 'her', 'charm', 'as', 'the', 'Tarleton', 'twins', 'were', '.', 'In', 'her', 'face', 'were', 'too', 'sharply', 'blended', 'the', 'delicate', 'features', 'of', 'her', 'mother', ',', 'a', 'Coast', 'aristocrat', 'of', 'French', 'descent', ',', 'and', 'the', 'heavy', 'ones', 'of', 'her', 'florid', 'Irish', 'father', '.', 'But', 'it', 'was', 'an', 'arresting', 'face', ',', 'pointed', 'of', 'chin', ',', 'square', 'of', 'jaw', '.', 'Her', 'eyes', 'were', 'pale', 'green', 'without', 'a', 'touch', 'of', 'hazel', ',', 'starred', 'with', 'bristly', 'black', 'lashes', 'and', 'slightly', 'tilted', 'at', 'the', 'ends', '.', 'Above', 'them', ',', 'her', 'thick', 'black', 'brows', 'slanted', 'upward', ',', 'cutting', 'a', 'startling', 'oblique', 'line', 'in', 'her', 'magnolia-white', 'skin', '--', 'that', 'skin', 'so', 'prized', 'by', 'Southern', 'women', 'and', 'so', 'carefully', 'guarded', 'with', 'bonnets', ',', 'veils', 'and', 'mittens', 'against', 'hot', 'Georgia', 'suns', '.']\n",
      "\n",
      "Stop Words Removed List: \n",
      "\n",
      " ['Scarlett', \"O'Hara\", 'beautiful', ',', 'men', 'seldom', 'realized', 'caught', 'charm', 'Tarleton', 'twins', '.', 'In', 'face', 'sharply', 'blended', 'delicate', 'features', 'mother', ',', 'Coast', 'aristocrat', 'French', 'descent', ',', 'heavy', 'ones', 'florid', 'Irish', 'father', '.', 'But', 'arresting', 'face', ',', 'pointed', 'chin', ',', 'square', 'jaw', '.', 'Her', 'eyes', 'pale', 'green', 'without', 'touch', 'hazel', ',', 'starred', 'bristly', 'black', 'lashes', 'slightly', 'tilted', 'ends', '.', 'Above', ',', 'thick', 'black', 'brows', 'slanted', 'upward', ',', 'cutting', 'startling', 'oblique', 'line', 'magnolia-white', 'skin', '--', 'skin', 'prized', 'Southern', 'women', 'carefully', 'guarded', 'bonnets', ',', 'veils', 'mittens', 'hot', 'Georgia', 'suns', '.']\n"
     ]
    }
   ],
   "source": [
    "#   Stop Words Removal\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "to_be_removed = set(stopwords.words('english'))\n",
    "print('Tokenized Text: \\n\\n',tokenized_text)\n",
    "\n",
    "stopWordsRemovedList = [word for word in tokenized_text if not word in to_be_removed]\n",
    "print('\\nStop Words Removed List: \\n\\n', stopWordsRemovedList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmed Words: \n",
      "\n",
      " ['scarlett', \"o'hara\", 'wa', 'not', 'beauti', ',', 'but', 'men', 'seldom', 'realiz', 'it', 'when', 'caught', 'by', 'her', 'charm', 'as', 'the', 'tarleton', 'twin', 'were', '.', 'in', 'her', 'face', 'were', 'too', 'sharpli', 'blend', 'the', 'delic', 'featur', 'of', 'her', 'mother', ',', 'a', 'coast', 'aristocrat', 'of', 'french', 'descent', ',', 'and', 'the', 'heavi', 'one', 'of', 'her', 'florid', 'irish', 'father', '.', 'but', 'it', 'wa', 'an', 'arrest', 'face', ',', 'point', 'of', 'chin', ',', 'squar', 'of', 'jaw', '.', 'her', 'eye', 'were', 'pale', 'green', 'without', 'a', 'touch', 'of', 'hazel', ',', 'star', 'with', 'bristli', 'black', 'lash', 'and', 'slightli', 'tilt', 'at', 'the', 'end', '.', 'abov', 'them', ',', 'her', 'thick', 'black', 'brow', 'slant', 'upward', ',', 'cut', 'a', 'startl', 'obliqu', 'line', 'in', 'her', 'magnolia-whit', 'skin', '--', 'that', 'skin', 'so', 'prize', 'by', 'southern', 'women', 'and', 'so', 'care', 'guard', 'with', 'bonnet', ',', 'veil', 'and', 'mitten', 'against', 'hot', 'georgia', 'sun', '.']\n",
      "\n",
      "Lancaster Stemmed Words: \n",
      "\n",
      " ['scarlet', \"o'hara\", 'was', 'not', 'beauty', ',', 'but', 'men', 'seldom', 'real', 'it', 'when', 'caught', 'by', 'her', 'charm', 'as', 'the', 'tarleton', 'twin', 'wer', '.', 'in', 'her', 'fac', 'wer', 'too', 'sharply', 'blend', 'the', 'del', 'feat', 'of', 'her', 'moth', ',', 'a', 'coast', 'aristocr', 'of', 'french', 'desc', ',', 'and', 'the', 'heavy', 'on', 'of', 'her', 'florid', 'ir', 'fath', '.', 'but', 'it', 'was', 'an', 'arrest', 'fac', ',', 'point', 'of', 'chin', ',', 'squ', 'of', 'jaw', '.', 'her', 'ey', 'wer', 'pal', 'green', 'without', 'a', 'touch', 'of', 'hazel', ',', 'star', 'with', 'brist', 'black', 'lash', 'and', 'slight', 'tilt', 'at', 'the', 'end', '.', 'abov', 'them', ',', 'her', 'thick', 'black', 'brow', 'slant', 'upward', ',', 'cut', 'a', 'startl', 'obl', 'lin', 'in', 'her', 'magnolia-white', 'skin', '--', 'that', 'skin', 'so', 'priz', 'by', 'southern', 'wom', 'and', 'so', 'car', 'guard', 'with', 'bonnet', ',', 'veil', 'and', 'mit', 'against', 'hot', 'georg', 'sun', '.']\n"
     ]
    }
   ],
   "source": [
    "#   Stemming\n",
    "#   There are different types of stemmers in NLTK library\n",
    "\n",
    "#   Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmerPort = PorterStemmer()\n",
    "\n",
    "portStemmedWords = [stemmerPort.stem(i) for i in tokenized_text]\n",
    "print('Porter Stemmed Words: \\n\\n',portStemmedWords)\n",
    "\n",
    "#   Lancaster Stemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "stemmerLan = LancasterStemmer()\n",
    "\n",
    "lanStemmedWords = [stemmerLan.stem(i) for i in tokenized_text]\n",
    "print('\\nLancaster Stemmed Words: \\n\\n',lanStemmedWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Words: \n",
      "\n",
      " ['Scarlett', \"O'Hara\", 'wa', 'not', 'beautiful', ',', 'but', 'men', 'seldom', 'realized', 'it', 'when', 'caught', 'by', 'her', 'charm', 'a', 'the', 'Tarleton', 'twin', 'were', '.', 'In', 'her', 'face', 'were', 'too', 'sharply', 'blended', 'the', 'delicate', 'feature', 'of', 'her', 'mother', ',', 'a', 'Coast', 'aristocrat', 'of', 'French', 'descent', ',', 'and', 'the', 'heavy', 'one', 'of', 'her', 'florid', 'Irish', 'father', '.', 'But', 'it', 'wa', 'an', 'arresting', 'face', ',', 'pointed', 'of', 'chin', ',', 'square', 'of', 'jaw', '.', 'Her', 'eye', 'were', 'pale', 'green', 'without', 'a', 'touch', 'of', 'hazel', ',', 'starred', 'with', 'bristly', 'black', 'lash', 'and', 'slightly', 'tilted', 'at', 'the', 'end', '.', 'Above', 'them', ',', 'her', 'thick', 'black', 'brow', 'slanted', 'upward', ',', 'cutting', 'a', 'startling', 'oblique', 'line', 'in', 'her', 'magnolia-white', 'skin', '--', 'that', 'skin', 'so', 'prized', 'by', 'Southern', 'woman', 'and', 'so', 'carefully', 'guarded', 'with', 'bonnet', ',', 'veil', 'and', 'mitten', 'against', 'hot', 'Georgia', 'sun', '.']\n"
     ]
    }
   ],
   "source": [
    "#   Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "lemmatizedWords = [lemmatizer.lemmatize(i) for i in tokenized_text]\n",
    "print('Lemmatized Words: \\n\\n',lemmatizedWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scarlett</th>\n",
       "      <th>O</th>\n",
       "      <th>’</th>\n",
       "      <th>Hara</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>,</th>\n",
       "      <th>men</th>\n",
       "      <th>seldom</th>\n",
       "      <th>realized</th>\n",
       "      <th>caught</th>\n",
       "      <th>...</th>\n",
       "      <th>carriage</th>\n",
       "      <th>dog</th>\n",
       "      <th>muzzle</th>\n",
       "      <th>paws</th>\n",
       "      <th>patiently</th>\n",
       "      <th>waiting</th>\n",
       "      <th>boys</th>\n",
       "      <th>go</th>\n",
       "      <th>home</th>\n",
       "      <th>supper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scarlett    O  ’  Hara  beautiful   ,  men  seldom  realized  caught  ...  \\\n",
       "0       1.0  1.0  1   1.0        1.0   9  1.0     1.0       1.0     1.0  ...   \n",
       "1       NaN  NaN  2   NaN        NaN  10  NaN     NaN       NaN     NaN  ...   \n",
       "2       NaN  NaN  3   NaN        NaN  20  NaN     NaN       NaN     NaN  ...   \n",
       "\n",
       "   carriage  dog  muzzle  paws  patiently  waiting  boys   go  home  supper  \n",
       "0       NaN  NaN     NaN   NaN        NaN      NaN   NaN  NaN   NaN     NaN  \n",
       "1       NaN  NaN     NaN   NaN        NaN      NaN   NaN  NaN   NaN     NaN  \n",
       "2       1.0  1.0     1.0   1.0        1.0      1.0   1.0  1.0   1.0     1.0  \n",
       "\n",
       "[3 rows x 252 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   Term Frequency and Inverse Document Frequency\n",
    "#   Create tokenized dataset for few sentences\n",
    "\n",
    "sent_1 = \"Scarlett O’Hara was not beautiful, but men seldom realized it when caught by her charm as the Tarleton twins were. In her face were too sharply blended the delicate features of her mother, a Coast aristocrat of French descent, and the heavy ones of her florid Irish father. But it was an arresting face, pointed of chin, square of jaw. Her eyes were pale green without a touch of hazel, starred with bristly black lashes and slightly tilted at the ends. Above them, her thick black brows slanted upward, cutting a startling oblique line in her magnolia-white skin--that skin so prized by Southern women and so carefully guarded with bonnets, veils and mittens against hot Georgia suns.\"\n",
    "sent_2 = \"Seated with Stuart and Brent Tarleton in the cool shade of the porch of Tara, her father’s plantation, that bright April afternoon of 1861, she made a pretty picture. Her new green flowered-muslin dress spread its twelve yards of billowing material over her hoops and exactly matched the flat-heeled green morocco slippers her father had recently brought her from Atlanta. The dress set off to perfection the seventeen-inch waist, the smallest in three counties, and the tightly fitting basque showed breasts well matured  for her sixteen years. But for all the modesty of her spreading skirts, the demureness of hair netted smoothly into a chignon and the quietness of small white hands folded in her lap, her true self was poorly concealed. The green eyes in the carefully sweet face were turbulent, willful, lusty with life, distinctly at variance with her decorous demeanor. Her manners had been imposed upon her by her mother’s gentle admonitions and the sterner discipline of her mammy; her eyes were her own.\"\n",
    "sent_3 = \"On either side of her, the twins lounged easily in their chairs, squinting at the sunlight through tall mint-garnished glasses as they laughed and talked, their long legs, booted to the knee and thick with saddle muscles, crossed negligently. Nineteen years old, six feet two inches tall, long of bone and hard of muscle, with sunburned faces and deep auburn hair, their eyes merry and arrogant, their bodies clothed in identical blue coats and mustard- colored breeches, they were as much alike as two bolls of cotton. Outside, the late afternoon sun slanted down in the yard, throwing into gleaming brightness the dogwood trees that were solid masses of white blossoms against the background of new green. The twins’ horses  were hitched in the driveway, big animals, red as their masters’  hair; and around the horses’ legs quarreled the pack of lean, nervous possum hounds that accompanied Stuart and Brent wherever they went. A little aloof, as became an aristocrat, lay a black-spotted carriage dog, muzzle on paws, patiently waiting for the boys to go home to supper.\"\n",
    "\n",
    "tk_sent_1 = nltk.word_tokenize(sent_1)\n",
    "tk_sent_2 = nltk.word_tokenize(sent_2)\n",
    "tk_sent_3 = nltk.word_tokenize(sent_3)\n",
    "\n",
    "#   Remove Stop Words\n",
    "tk_sent_1 = [word for word in tk_sent_1 if not word in to_be_removed]\n",
    "tk_sent_2 = [word for word in tk_sent_2 if not word in to_be_removed]\n",
    "tk_sent_3 = [word for word in tk_sent_3 if not word in to_be_removed]\n",
    "\n",
    "#   We have the tokenized word dataset, lets create a way to count the words using dictionary key-value pairing \n",
    "\n",
    "\n",
    "wordDict_1 = dict.fromkeys(tk_sent_1, 0)\n",
    "for word in tk_sent_1:\n",
    "    wordDict_1[word]+=1\n",
    "\n",
    "wordDict_2 = dict.fromkeys(tk_sent_2, 0)\n",
    "for word in tk_sent_2:\n",
    "    wordDict_2[word]+=1\n",
    "\n",
    "wordDict_3 = dict.fromkeys(tk_sent_3, 0)\n",
    "for word in tk_sent_3:\n",
    "    wordDict_3[word]+=1\n",
    "    \n",
    "#   put them into a dataframe\n",
    "doc = pd.DataFrame([wordDict_1, wordDict_2, wordDict_3])\n",
    "doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scarlett</th>\n",
       "      <th>O</th>\n",
       "      <th>’</th>\n",
       "      <th>Hara</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>,</th>\n",
       "      <th>men</th>\n",
       "      <th>seldom</th>\n",
       "      <th>realized</th>\n",
       "      <th>caught</th>\n",
       "      <th>...</th>\n",
       "      <th>carriage</th>\n",
       "      <th>dog</th>\n",
       "      <th>muzzle</th>\n",
       "      <th>paws</th>\n",
       "      <th>patiently</th>\n",
       "      <th>waiting</th>\n",
       "      <th>boys</th>\n",
       "      <th>go</th>\n",
       "      <th>home</th>\n",
       "      <th>supper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scarlett         O         ’      Hara  beautiful         ,       men  \\\n",
       "0  0.011364  0.011364  0.011364  0.011364   0.011364  0.102273  0.011364   \n",
       "1  0.011364  0.011364  0.011364  0.011364   0.011364  0.102273  0.011364   \n",
       "2       NaN       NaN  0.020833       NaN        NaN  0.138889       NaN   \n",
       "\n",
       "     seldom  realized    caught  ...  carriage       dog    muzzle      paws  \\\n",
       "0  0.011364  0.011364  0.011364  ...       NaN       NaN       NaN       NaN   \n",
       "1  0.011364  0.011364  0.011364  ...       NaN       NaN       NaN       NaN   \n",
       "2       NaN       NaN       NaN  ...  0.006944  0.006944  0.006944  0.006944   \n",
       "\n",
       "   patiently   waiting      boys        go      home    supper  \n",
       "0        NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "1        NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2   0.006944  0.006944  0.006944  0.006944  0.006944  0.006944  \n",
       "\n",
       "[3 rows x 176 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   TF Function\n",
    "def computeTF(wordDict, doc):\n",
    "    tfDict = {}\n",
    "    corpusCount = len(doc)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(corpusCount)\n",
    "    return(tfDict)\n",
    "#running our sentences through the tf function:\n",
    "tfFirst = computeTF(wordDict_1, tk_sent_1)\n",
    "tfSecond = computeTF(wordDict_1, tk_sent_1)\n",
    "tfThird = computeTF(wordDict_3, tk_sent_3)\n",
    "\n",
    "#Converting to dataframe for visualization\n",
    "tf = pd.DataFrame([tfFirst, tfSecond, tfThird])\n",
    "\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Scarlett         O         ’      Hara  beautiful         ,       men  \\\n",
      "0  0.005422  0.005422  0.005422  0.005422   0.005422  0.048796  0.005422   \n",
      "1  0.005422  0.005422  0.005422  0.005422   0.005422  0.048796  0.005422   \n",
      "\n",
      "     seldom  realized    caught  ...  Southern     women  carefully   guarded  \\\n",
      "0  0.005422  0.005422  0.005422  ...  0.005422  0.005422   0.005422  0.005422   \n",
      "1  0.005422  0.005422  0.005422  ...  0.005422  0.005422   0.005422  0.005422   \n",
      "\n",
      "    bonnets     veils   mittens       hot   Georgia      suns  \n",
      "0  0.005422  0.005422  0.005422  0.005422  0.005422  0.005422  \n",
      "1  0.005422  0.005422  0.005422  0.005422  0.005422  0.005422  \n",
      "\n",
      "[2 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "#   IDF Function\n",
    "def computeIDF(docList):\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / (float(val) + 1))\n",
    "        \n",
    "    return(idfDict)\n",
    "#   inputing our sentences in the log file\n",
    "idfs = computeIDF([wordDict_1, wordDict_2, wordDict_3])\n",
    "\n",
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)\n",
    "#   running our two sentences through the IDF:\n",
    "idfFirst = computeTFIDF(tfFirst, idfs)\n",
    "idfSecond = computeTFIDF(tfSecond, idfs)\n",
    "\n",
    "#   putting it in a dataframe\n",
    "idf= pd.DataFrame([idfFirst, idfSecond])\n",
    "print(idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Reference Links:\n",
    "#   Text Analytics Guide : Towards Data Science : https://towardsdatascience.com/a-guide-text-analysis-text-analytics-text-mining-f62df7b78747\n",
    "\n",
    "#   NLTK Guide: https://www.mygreatlearning.com/blog/nltk-tutorial-with-python/#:~:text=A%20dataset%20is%20referred%20to,would%20see%20in%20later%20sections.\n",
    "\n",
    "#   TD/IDF Guide: https://towardsdatascience.com/tf-term-frequency-idf-inverse-document-frequency-from-scratch-in-python-6c2b61b78558#:~:text=To%20further%20distinguish%20them%2C%20we,proportional%20to%20the%20term%20frequency."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0144baad0ecee903f108a3e46e51ceadd7da3fc904cfa79747d813b61464b4e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
